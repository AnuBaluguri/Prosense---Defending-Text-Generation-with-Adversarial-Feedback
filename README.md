# Prosense: Defending Text Generation with Adversarial Feedback

Prosense is a multi-stage training framework designed to improve the robustness of large language models (LLMs) against adversarial inputs. It fine-tunes quantized LLMs using clean and adversarially augmented datasets, evaluates model performance via structured reasoning, and iteratively refines the model through curriculum-based adversarial feedback.

> ğŸš€ **Model Base**: `unsloth/mistral-7b-bnb-4bit`  
> ğŸ§  **Goal**: Improve response truthfulness and adversarial resilience via multi-stage fine-tuning  
> ğŸ§ª **Datasets**: Open-Instruct, TruthfulQA

---

## ğŸ“ Project Structure

```
Prosense-Adversarial-Robustness/
â”‚
â”œâ”€â”€ Phase1_Clean_FineTuning/
â”‚   â””â”€â”€ phase1.ipynb
â”‚
â”œâ”€â”€ Phase2_Adversarial_Hybrid/
â”‚   â”œâ”€â”€ HybridDataCreation.ipynb
â”‚   â”œâ”€â”€ MergingWithHybridDataset.ipynb
â”‚   â””â”€â”€ Phase2_Final.ipynb
â”‚
â”œâ”€â”€ Phase3_Evaluation_Parsing/
â”‚   â”œâ”€â”€ Phase2_Model_Responses_Collection_Code.ipynb
â”‚   â”œâ”€â”€ Parsing_GOT_Style_By_Llama_Code.ipynb
â”‚   â””â”€â”€ Phase3_Final.ipynb
â”‚
â””â”€â”€ Phase3_Level2_Refinement/
    â”œâ”€â”€ Level1_Model_Responses_Collection_Code.ipynb
    â”œâ”€â”€ Level1_Model_Responses_Judging&Parsing_Llama_Code.ipynb
    â”œâ”€â”€ Phase3_Level2_Finetuning_Code.ipynb
    â”œâ”€â”€ Phase3_Level2_Model_Responses_Collection_Code.ipynb
    â””â”€â”€ Reasoning_graphs.ipynb
```

---

## ğŸ“Œ Methodology & Pipeline

### ğŸ”¹ Phase 1 â€“ Baseline Fine-Tuning
Fine-tunes a 4-bit quantized Mistral-7B model using the Open-Instruct dataset.  
Includes preprocessing, tokenization, and model checkpoint saving.

> Output: `mistral-prosense-clean` (baseline model)

---

### ğŸ”¹ Phase 2 â€“ Adversarial Hybrid Fine-Tuning
Generates adversarial examples using perturbation-based attacks, merges them with clean samples, and retrains the model on this hybrid dataset.

> Output: `mistral-prosense-hybrid` (model trained on mixed data)

---

### ğŸ”¹ Phase 3 â€“ Evaluation, Parsing, and CoT Fine-Tuning
Evaluates the hybrid model on TruthfulQA, collects failed responses, and uses LLaMA to parse them into Chain-of-Thought (CoT) style structured reasoning. This data is used to fine-tune the model further.

> Output: `mistral-prosense-parsed` (CoT-refined model)

---

### ğŸ”¹ Phase 3 Again â€“ Level 2 Feedback and Final Evaluation
Repeats evaluation and parsing on the Level 1 model, followed by one more round of fine-tuning and final performance judging. Also generates reasoning graphs for qualitative analysis.

> Output: Final `mistral-finetuning-again` + reasoning graph insights

---

## ğŸ› ï¸ Dependencies

Create a new environment and install these key packages:

```bash
pip install transformers accelerate datasets bitsandbytes unsloth
pip install textattack  # or OpenAttack if used
```

Python â‰¥ 3.10 is recommended. GPU with 24GB+ VRAM for fine-tuning.

---

## ğŸš€ Getting Started

1. **Clone the repository**  
   `git clone https://github.com/your-username/Prosense-Adversarial-Robustness.git`

2. **Set up your environment**  
   Install the dependencies listed above or use a `requirements.txt`.

3. **Run each phase**  
   Open and run the Jupyter notebooks in sequence, starting from Phase 1.

---

## ğŸ“Š Evaluation Results (Optional)
You can add metrics here if you tracked model performance across stages, such as:

- TruthfulQA Pass Rate: 35% â†’ 55% (Post Phase 3)
- Adversarial Robustness Improvement: +30%

---


## ğŸ“„ License

This project is intended for academic and research use. Please cite appropriately if you reuse or adapt this pipeline.

